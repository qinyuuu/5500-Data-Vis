{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-world Data Science: Applications of Visualization\n",
    "## Qinyu Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='crowwwww56', api_key='YNELI27nGE9bz8ZSFaxZ')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"wine-reviews/winemag-data-130k-v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4           4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129971 entries, 0 to 129970\n",
      "Data columns (total 14 columns):\n",
      "Unnamed: 0               129971 non-null int64\n",
      "country                  129908 non-null object\n",
      "description              129971 non-null object\n",
      "designation              92506 non-null object\n",
      "points                   129971 non-null int64\n",
      "price                    120975 non-null float64\n",
      "province                 129908 non-null object\n",
      "region_1                 108724 non-null object\n",
      "region_2                 50511 non-null object\n",
      "taster_name              103727 non-null object\n",
      "taster_twitter_handle    98758 non-null object\n",
      "title                    129971 non-null object\n",
      "variety                  129970 non-null object\n",
      "winery                   129971 non-null object\n",
      "dtypes: float64(1), int64(2), object(11)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>129971.000000</td>\n",
       "      <td>129971.000000</td>\n",
       "      <td>120975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>64985.000000</td>\n",
       "      <td>88.447138</td>\n",
       "      <td>35.363389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37519.540256</td>\n",
       "      <td>3.039730</td>\n",
       "      <td>41.022218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32492.500000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64985.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>97477.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>129970.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0         points          price\n",
       "count  129971.000000  129971.000000  120975.000000\n",
       "mean    64985.000000      88.447138      35.363389\n",
       "std     37519.540256       3.039730      41.022218\n",
       "min         0.000000      80.000000       4.000000\n",
       "25%     32492.500000      86.000000      17.000000\n",
       "50%     64985.000000      88.000000      25.000000\n",
       "75%     97477.500000      91.000000      42.000000\n",
       "max    129970.000000     100.000000    3300.000000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for all clients.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~crowwwww56/55.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualization 1: scatter plot\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x = data['price'],\n",
    "    y = data['points'],\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "data_v1 = [trace]\n",
    "\n",
    "layout = dict(title = 'relationship between wine price and points',\n",
    "              xaxis = dict(title = 'price'),\n",
    "              yaxis = dict(title = 'points'),\n",
    "              )\n",
    "fig_scatter = dict(data=data_v1, layout=layout)\n",
    "py.iplot(fig_scatter, filename='scatter_plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first visualization is a scatter plot. I use point mark and position channel to encode wine points and wine price. I also add an interaction that when a user hovers on a certain point, its accurate wine points and wine price number will show up. The interaction is helpful when a user wants to know the detailed number of each point. This visualization addressed the task of examining the relationship between wine points and wine price. As we can see from the plot, there is a slight logarithm relationship between wine points and wine price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~crowwwww56/57.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualization 2: choropleth map\n",
    "\n",
    "counts = data['country'].value_counts()\n",
    "\n",
    "trace = go.Choropleth(\n",
    "    locationmode = 'country names',\n",
    "    locations = country_counts.index.values,\n",
    "    colorscale = [[0,\"rgb(226, 183, 200)\"],[0.5,\"rgb(153, 65, 100)\"],[1,\"rgb(147, 19, 70)\"]],\n",
    "    text = country_counts.index,\n",
    "    z = country_counts.values\n",
    ")\n",
    "\n",
    "data_v2 = [trace]\n",
    "\n",
    "layout = dict(title = 'where the wine reviews were made from')\n",
    "fig_map = dict(data=data_v2, layout=layout)\n",
    "py.iplot(fig_map, filename='map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second visualization is a choropleth map. I use area mark to and position channel to encode geo-location. The color channel is used to encode review number. I also add an interaction that when a user hovers on a certain area, the country name and corresponding review number will appear which helps users to know detailed information about what is the country and what is the number of wine reviews. This visualization addressed the task of examing where most of the wine reviews were made from. As we can see from the plot, most of the wine reviews were made from the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns, duplicates, na\n",
    "\n",
    "# 'Unnamed: 0' is not related \n",
    "# 'designation', 'region_2,taster_twitter_handle' containing too many nan\n",
    "# use 'description' instead of 'title'\n",
    "data = data.drop(columns = ['Unnamed: 0','region_2','designation','taster_twitter_handle','title'])\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna()\n",
    "\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Navarra</td>\n",
       "      <td>Michael Schachner</td>\n",
       "      <td>Tempranillo-Merlot</td>\n",
       "      <td>Tandem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Here's a bright, informal red that opens with ...</td>\n",
       "      <td>87</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Vittoria</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>Frappato</td>\n",
       "      <td>Terre di Giurfo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  points  price  \\\n",
       "0      US  Tart and snappy, the flavors of lime flesh and...      87   14.0   \n",
       "1      US  Pineapple rind, lemon pith and orange blossom ...      87   13.0   \n",
       "2      US  Much like the regular bottling from 2012, this...      87   65.0   \n",
       "3   Spain  Blackberry and raspberry aromas show a typical...      87   15.0   \n",
       "4   Italy  Here's a bright, informal red that opens with ...      87   16.0   \n",
       "\n",
       "            province             region_1         taster_name  \\\n",
       "0             Oregon    Willamette Valley        Paul Gregutt   \n",
       "1           Michigan  Lake Michigan Shore  Alexander Peartree   \n",
       "2             Oregon    Willamette Valley        Paul Gregutt   \n",
       "3     Northern Spain              Navarra   Michael Schachner   \n",
       "4  Sicily & Sardinia             Vittoria       Kerin O’Keefe   \n",
       "\n",
       "              variety           winery  \n",
       "0          Pinot Gris        Rainstorm  \n",
       "1            Riesling       St. Julian  \n",
       "2          Pinot Noir     Sweet Cheeks  \n",
       "3  Tempranillo-Merlot           Tandem  \n",
       "4            Frappato  Terre di Giurfo  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing random subset of the dataset\n",
    "\n",
    "data = data.sample(n=10000)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>Richer scents of maple smoke and bacon fat int...</td>\n",
       "      <td>92</td>\n",
       "      <td>55.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Cruz Mountains</td>\n",
       "      <td>Matt Kettmann</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Big Basin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Smoky, charred aromas are rugged and center ar...</td>\n",
       "      <td>89</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Catalonia</td>\n",
       "      <td>Montsant</td>\n",
       "      <td>Michael Schachner</td>\n",
       "      <td>Red Blend</td>\n",
       "      <td>Bula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>This blend of Roussanne, Viognier, Marsanne an...</td>\n",
       "      <td>86</td>\n",
       "      <td>24.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Clara Valley</td>\n",
       "      <td>Matt Kettmann</td>\n",
       "      <td>Rhône-style White Blend</td>\n",
       "      <td>Sarah's Vineyard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>A bit reduced when first opened, it throws off...</td>\n",
       "      <td>89</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Panther Creek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Always in the top rank of Oregon Chardonnays, ...</td>\n",
       "      <td>93</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Bergström</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  points  price  \\\n",
       "0      US  Richer scents of maple smoke and bacon fat int...      92   55.0   \n",
       "1   Spain  Smoky, charred aromas are rugged and center ar...      89   15.0   \n",
       "2      US  This blend of Roussanne, Viognier, Marsanne an...      86   24.0   \n",
       "3      US  A bit reduced when first opened, it throws off...      89   60.0   \n",
       "4      US  Always in the top rank of Oregon Chardonnays, ...      93   85.0   \n",
       "\n",
       "     province              region_1        taster_name  \\\n",
       "0  California  Santa Cruz Mountains      Matt Kettmann   \n",
       "1   Catalonia              Montsant  Michael Schachner   \n",
       "2  California    Santa Clara Valley      Matt Kettmann   \n",
       "3      Oregon     Willamette Valley       Paul Gregutt   \n",
       "4      Oregon     Willamette Valley       Paul Gregutt   \n",
       "\n",
       "                   variety            winery  \n",
       "0                    Syrah         Big Basin  \n",
       "1                Red Blend              Bula  \n",
       "2  Rhône-style White Blend  Sarah's Vineyard  \n",
       "3               Pinot Noir     Panther Creek  \n",
       "4               Chardonnay         Bergström  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country         object\n",
       "description     object\n",
       "points           int64\n",
       "price          float64\n",
       "province        object\n",
       "region_1        object\n",
       "taster_name     object\n",
       "variety         object\n",
       "winery          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6153)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding for categorical columns \n",
    "\n",
    "data = pd.get_dummies(data, columns = [\"country\",\"province\",\"region_1\",\"taster_name\",\"variety\",\"winery\"])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text data by removing stop words, stemming\n",
    "\n",
    "stopwords = []\n",
    "with open('stopwords_english.txt') as fsw:\n",
    "    for word in fsw.readlines():\n",
    "        word = word.strip('\\n')\n",
    "        stopwords.append(word)\n",
    "fsw.close()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "    text = text.apply(lambda x: \" \".join(x.strip() for x in str(x).split()))\n",
    "    text = text.apply(lambda x: \"\".join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
    "    text = text.str.replace('[^\\w\\s]', '')\n",
    "    text = text.str.replace('\\d+', '')\n",
    "    text = text.apply(lambda x: \" \".join([word for word in str(x).split() if word not in (stopwords)]))\n",
    "    text = text.astype(str)\n",
    "    return text\n",
    "data['description'] = preprocess_text(data['description'])\n",
    "\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "def stem(text):\n",
    "    text = text.apply(lambda x: \" \".join([ps.stem(x) for x in str(x).split()]))\n",
    "    return text\n",
    "data['description'] = stem(data['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    richer scent mapl smoke bacon fat integr well ...\n",
       "1    smoki char aroma rug center around black fruit...\n",
       "2    blend roussann viognier marsann grenach blanc ...\n",
       "3    bit reduc first open throw scent burnt rubber ...\n",
       "4    alway top rank oregon chardonnay sigrid expres...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train set and test set\n",
    "\n",
    "train, test = train_test_split(data,test_size=0.2,random_state=0)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 6153), (2000, 6153))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize quantitative columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train[['price','points']] = scaler.fit_transform(train[['price','points']])\n",
    "test[['price','points']] = scaler.transform(test[['price','points']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train = train.drop(['points'],axis=1)\n",
    "X_test = test.drop(['points'],axis=1)\n",
    "y_train = train['points']\n",
    "y_test = test['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 6153), (2000, 6153), (8000, 6152), (2000, 6152), (8000,), (2000,))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(sublinear_tf = True)\n",
    "train_text = vectorizer.fit_transform(X_train.description)\n",
    "test_text = vectorizer.transform(X_test.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "lda = LatentDirichletAllocation(n_components=10)\n",
    "train_text = lda.fit_transform(train_text)\n",
    "test_text = lda.transform(test_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.01346341, 0.01346045, 0.01346045, ..., 0.01346066, 0.69901897,\n",
       "         0.19327194],\n",
       "        [0.01948744, 0.01948392, 0.01948391, ..., 0.01948411, 0.1285686 ,\n",
       "         0.71554911],\n",
       "        [0.01640964, 0.01640251, 0.01640291, ..., 0.01640476, 0.28678448,\n",
       "         0.01640734],\n",
       "        ...,\n",
       "        [0.01922967, 0.01922709, 0.01922708, ..., 0.01922713, 0.01923028,\n",
       "         0.69902401],\n",
       "        [0.01858144, 0.01857597, 0.01857609, ..., 0.01857708, 0.01858217,\n",
       "         0.01858128],\n",
       "        [0.01694701, 0.01693673, 0.01693668, ..., 0.01693759, 0.01694288,\n",
       "         0.8474866 ]]),\n",
       " array([[0.01766421, 0.01765906, 0.01765906, ..., 0.01766062, 0.55001513,\n",
       "         0.01766404],\n",
       "        [0.26977744, 0.01526353, 0.01526356, ..., 0.01527003, 0.18518579,\n",
       "         0.01526698],\n",
       "        [0.71879608, 0.01565238, 0.01565239, ..., 0.01565292, 0.07484346,\n",
       "         0.01565797],\n",
       "        ...,\n",
       "        [0.01767736, 0.01766532, 0.01768203, ..., 0.0176654 , 0.26980292,\n",
       "         0.4072169 ],\n",
       "        [0.01694285, 0.18835626, 0.01693107, ..., 0.01693182, 0.01694253,\n",
       "         0.01693722],\n",
       "        [0.01793454, 0.01793091, 0.01793092, ..., 0.01793161, 0.01793885,\n",
       "         0.01793484]]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text,test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preprocessed X_train, X_test, y_train, y_test\n",
    "\n",
    "# drop 'description' from X_train, X_test\n",
    "X_train_preprocessed = X_train.drop(['description'],axis=1)\n",
    "X_test_preprocessed = X_test.drop(['description'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lda result array into dataframe\n",
    "train_lda = pd.DataFrame(train_text)\n",
    "test_lda = pd.DataFrame(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat lda df and X_train_preprocessed\n",
    "X_train_preprocessed2 = pd.concat([train_lda,X_train_preprocessed],axis = 1)\n",
    "X_test_preprocessed2 = pd.concat([test_lda,X_test_preprocessed],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 6151), (8000, 10), (8000, 6161))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed.shape,train_lda.shape,X_train_preprocessed2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values\n",
    "X_train_preprocessed3 = X_train_preprocessed2.values\n",
    "X_test_preprocessed3 = X_test_preprocessed2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_preprocessed3, X_test_preprocessed3, y_train, y_test\n",
    "# X_train_preprocessed2, X_test_preprocessed2 containing feature name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did these following steps to preprocessed the data:  \n",
    "1) Drop 'Unnamed: 0' column since it is not related to points, drop 'designation', 'region_2', 'taster_twitter_handle' since they contain too many nan values, drop 'title' column since I will only use 'description' column.    \n",
    "2) I did one-hot encoding for categorical columns including 'country', 'province', 'region_1', 'taster_name', 'variety', 'winery' to transfer them into numeric features.  \n",
    "3) I cleaned text data by removing stop words and non-English words, then did stemming on words aiming at increasing model accuracy.  \n",
    "4) I split the dataset into the training set and testing set.  \n",
    "5) I standardized the quantitative columns separately on the training set and testing set to avoid data leakage.  \n",
    "6) I did TF-IDF and LDA separately on the training set and testing set to transfer text feature into numeric features.  \n",
    "7) I concatenate data frames to get the final X_train, X_test, y_train, and y_test.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use Ridge Regression, Lasso Regression and Gradient Boosting Regression Tree algorithms to predict wine points.  \n",
    "For Ridge Regression, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.733806</td>\n",
       "      <td>0.973171</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.787262</td>\n",
       "      <td>0.761715</td>\n",
       "      <td>0.815979</td>\n",
       "      <td>0.806497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144683</td>\n",
       "      <td>0.141078</td>\n",
       "      <td>0.142389</td>\n",
       "      <td>0.144250</td>\n",
       "      <td>0.143516</td>\n",
       "      <td>0.143877</td>\n",
       "      <td>0.144322</td>\n",
       "      <td>0.145325</td>\n",
       "      <td>0.144052</td>\n",
       "      <td>0.001366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.157740</td>\n",
       "      <td>0.512551</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>0.719892</td>\n",
       "      <td>0.701474</td>\n",
       "      <td>0.745088</td>\n",
       "      <td>0.752042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146774</td>\n",
       "      <td>0.143038</td>\n",
       "      <td>0.144392</td>\n",
       "      <td>0.146281</td>\n",
       "      <td>0.145621</td>\n",
       "      <td>0.145799</td>\n",
       "      <td>0.146450</td>\n",
       "      <td>0.147162</td>\n",
       "      <td>0.146056</td>\n",
       "      <td>0.001359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.784624</td>\n",
       "      <td>1.069327</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.687170</td>\n",
       "      <td>0.668122</td>\n",
       "      <td>0.708644</td>\n",
       "      <td>0.725515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150096</td>\n",
       "      <td>0.146265</td>\n",
       "      <td>0.147619</td>\n",
       "      <td>0.149513</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.148982</td>\n",
       "      <td>0.149861</td>\n",
       "      <td>0.150306</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.166955</td>\n",
       "      <td>1.357433</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.599629</td>\n",
       "      <td>0.568113</td>\n",
       "      <td>0.605999</td>\n",
       "      <td>0.628120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228359</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>0.225501</td>\n",
       "      <td>0.227226</td>\n",
       "      <td>0.225506</td>\n",
       "      <td>0.226523</td>\n",
       "      <td>0.229464</td>\n",
       "      <td>0.229220</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>0.001664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.229806</td>\n",
       "      <td>0.756335</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5.0}</td>\n",
       "      <td>0.600969</td>\n",
       "      <td>0.567533</td>\n",
       "      <td>0.600193</td>\n",
       "      <td>0.615376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399479</td>\n",
       "      <td>0.397520</td>\n",
       "      <td>0.395634</td>\n",
       "      <td>0.398731</td>\n",
       "      <td>0.395789</td>\n",
       "      <td>0.397423</td>\n",
       "      <td>0.403685</td>\n",
       "      <td>0.404113</td>\n",
       "      <td>0.399296</td>\n",
       "      <td>0.002844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0      10.733806      0.973171         0.012265        0.003188        0.01   \n",
       "1      10.157740      0.512551         0.010868        0.000536        0.05   \n",
       "2      10.784624      1.069327         0.011869        0.002017         0.1   \n",
       "3      11.166955      1.357433         0.011768        0.001601           1   \n",
       "4      11.229806      0.756335         0.012467        0.001561           5   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.01}           0.787262           0.761715           0.815979   \n",
       "1  {'alpha': 0.05}           0.719892           0.701474           0.745088   \n",
       "2   {'alpha': 0.1}           0.687170           0.668122           0.708644   \n",
       "3   {'alpha': 1.0}           0.599629           0.568113           0.605999   \n",
       "4   {'alpha': 5.0}           0.600969           0.567533           0.600193   \n",
       "\n",
       "   split3_test_score       ...         split2_train_score  split3_train_score  \\\n",
       "0           0.806497       ...                   0.144683            0.141078   \n",
       "1           0.752042       ...                   0.146774            0.143038   \n",
       "2           0.725515       ...                   0.150096            0.146265   \n",
       "3           0.628120       ...                   0.228359            0.224719   \n",
       "4           0.615376       ...                   0.399479            0.397520   \n",
       "\n",
       "   split4_train_score  split5_train_score  split6_train_score  \\\n",
       "0            0.142389            0.144250            0.143516   \n",
       "1            0.144392            0.146281            0.145621   \n",
       "2            0.147619            0.149513            0.148804   \n",
       "3            0.225501            0.227226            0.225506   \n",
       "4            0.395634            0.398731            0.395789   \n",
       "\n",
       "   split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0            0.143877            0.144322            0.145325   \n",
       "1            0.145799            0.146450            0.147162   \n",
       "2            0.148982            0.149861            0.150306   \n",
       "3            0.226523            0.229464            0.229220   \n",
       "4            0.397423            0.403685            0.404113   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.144052         0.001366  \n",
       "1          0.146056         0.001359  \n",
       "2          0.149300         0.001371  \n",
       "3          0.227406         0.001664  \n",
       "4          0.399296         0.002844  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "grid = GridSearchCV(estimator = Ridge(), param_grid = {'alpha':[0.01,0.05,0.1,1.0,5.0]}, scoring =mse, cv = 10, return_train_score=True).fit(X_train_preprocessed3, y_train)\n",
    "result = pd.DataFrame(grid.cv_results_)\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.787262</td>\n",
       "      <td>0.719892</td>\n",
       "      <td>0.687170</td>\n",
       "      <td>0.599629</td>\n",
       "      <td>0.600969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.761715</td>\n",
       "      <td>0.701474</td>\n",
       "      <td>0.668122</td>\n",
       "      <td>0.568113</td>\n",
       "      <td>0.567533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.815979</td>\n",
       "      <td>0.745088</td>\n",
       "      <td>0.708644</td>\n",
       "      <td>0.605999</td>\n",
       "      <td>0.600193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.806497</td>\n",
       "      <td>0.752042</td>\n",
       "      <td>0.725515</td>\n",
       "      <td>0.628120</td>\n",
       "      <td>0.615376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.852745</td>\n",
       "      <td>0.795485</td>\n",
       "      <td>0.763671</td>\n",
       "      <td>0.655276</td>\n",
       "      <td>0.657021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>0.789013</td>\n",
       "      <td>0.735550</td>\n",
       "      <td>0.705352</td>\n",
       "      <td>0.606789</td>\n",
       "      <td>0.610207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>0.773944</td>\n",
       "      <td>0.716979</td>\n",
       "      <td>0.694075</td>\n",
       "      <td>0.627100</td>\n",
       "      <td>0.637492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>0.755212</td>\n",
       "      <td>0.714371</td>\n",
       "      <td>0.692704</td>\n",
       "      <td>0.619727</td>\n",
       "      <td>0.624472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>0.750177</td>\n",
       "      <td>0.684217</td>\n",
       "      <td>0.650797</td>\n",
       "      <td>0.543006</td>\n",
       "      <td>0.531306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>0.692356</td>\n",
       "      <td>0.647999</td>\n",
       "      <td>0.624029</td>\n",
       "      <td>0.533016</td>\n",
       "      <td>0.519839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0.01      0.05       0.1         1         5\n",
       "split0_test_score  0.787262  0.719892  0.687170  0.599629  0.600969\n",
       "split1_test_score  0.761715  0.701474  0.668122  0.568113  0.567533\n",
       "split2_test_score  0.815979  0.745088  0.708644  0.605999  0.600193\n",
       "split3_test_score  0.806497  0.752042  0.725515  0.628120  0.615376\n",
       "split4_test_score  0.852745  0.795485  0.763671  0.655276  0.657021\n",
       "split5_test_score  0.789013  0.735550  0.705352  0.606789  0.610207\n",
       "split6_test_score  0.773944  0.716979  0.694075  0.627100  0.637492\n",
       "split7_test_score  0.755212  0.714371  0.692704  0.619727  0.624472\n",
       "split8_test_score  0.750177  0.684217  0.650797  0.543006  0.531306\n",
       "split9_test_score  0.692356  0.647999  0.624029  0.533016  0.519839"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_filtered2 = result[[\"split0_test_score\",\"split1_test_score\",\"split2_test_score\",\"split3_test_score\",\"split4_test_score\",\"split5_test_score\",\"split6_test_score\",\"split7_test_score\",\"split8_test_score\",\"split9_test_score\"]]\n",
    "result_filtered3_ridge = np.transpose(result_filtered2)\n",
    "result_filtered3_ridge.columns = ['0.01','0.05','0.1','1','5']\n",
    "result_filtered3_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'alpha')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_filtered3_ridge.boxplot()\n",
    "plt.title(\"ridge regression\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.xlabel(\"alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'alpha')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "grid = GridSearchCV(estimator = Lasso(), param_grid = {'alpha':[0.01,0.05,0.1,1.0,5.0]}, scoring =mse, cv = 10, return_train_score=True).fit(X_train_preprocessed3, y_train)\n",
    "result = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "result_filtered2 = result[[\"split0_test_score\",\"split1_test_score\",\"split2_test_score\",\"split3_test_score\",\"split4_test_score\",\"split5_test_score\",\"split6_test_score\",\"split7_test_score\",\"split8_test_score\",\"split9_test_score\"]]\n",
    "result_filtered3_lasso = np.transpose(result_filtered2)\n",
    "result_filtered3_lasso.columns = ['0.01','0.05','0.1','1','5']\n",
    "\n",
    "result_filtered3_lasso.boxplot()\n",
    "plt.title(\"lasso regression\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.xlabel(\"alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.026700</td>\n",
       "      <td>0.260215</td>\n",
       "      <td>0.020645</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 25, 's...</td>\n",
       "      <td>0.793623</td>\n",
       "      <td>0.835415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.825115</td>\n",
       "      <td>0.828734</td>\n",
       "      <td>0.827507</td>\n",
       "      <td>0.828922</td>\n",
       "      <td>0.828876</td>\n",
       "      <td>0.833301</td>\n",
       "      <td>0.841282</td>\n",
       "      <td>0.830884</td>\n",
       "      <td>0.004457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.980678</td>\n",
       "      <td>0.179243</td>\n",
       "      <td>0.021446</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 25, 's...</td>\n",
       "      <td>0.792276</td>\n",
       "      <td>0.834645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.826020</td>\n",
       "      <td>0.829009</td>\n",
       "      <td>0.827749</td>\n",
       "      <td>0.829333</td>\n",
       "      <td>0.829420</td>\n",
       "      <td>0.833678</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.831280</td>\n",
       "      <td>0.004438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.139601</td>\n",
       "      <td>0.174975</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 25, 's...</td>\n",
       "      <td>0.793491</td>\n",
       "      <td>0.836605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830612</td>\n",
       "      <td>0.825974</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>0.828113</td>\n",
       "      <td>0.830659</td>\n",
       "      <td>0.830416</td>\n",
       "      <td>0.834267</td>\n",
       "      <td>0.842854</td>\n",
       "      <td>0.831923</td>\n",
       "      <td>0.004495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.704232</td>\n",
       "      <td>0.366242</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 50, 's...</td>\n",
       "      <td>0.686398</td>\n",
       "      <td>0.729281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720222</td>\n",
       "      <td>0.716070</td>\n",
       "      <td>0.718915</td>\n",
       "      <td>0.718778</td>\n",
       "      <td>0.718094</td>\n",
       "      <td>0.719638</td>\n",
       "      <td>0.723139</td>\n",
       "      <td>0.728912</td>\n",
       "      <td>0.720774</td>\n",
       "      <td>0.003519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.308612</td>\n",
       "      <td>0.591235</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 50, 's...</td>\n",
       "      <td>0.687524</td>\n",
       "      <td>0.729157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720687</td>\n",
       "      <td>0.716899</td>\n",
       "      <td>0.720208</td>\n",
       "      <td>0.719302</td>\n",
       "      <td>0.719525</td>\n",
       "      <td>0.719583</td>\n",
       "      <td>0.723224</td>\n",
       "      <td>0.729401</td>\n",
       "      <td>0.721479</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>122.811179</td>\n",
       "      <td>2.825839</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 50, 's...</td>\n",
       "      <td>0.688819</td>\n",
       "      <td>0.731255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721694</td>\n",
       "      <td>0.718104</td>\n",
       "      <td>0.720822</td>\n",
       "      <td>0.719624</td>\n",
       "      <td>0.721509</td>\n",
       "      <td>0.721375</td>\n",
       "      <td>0.724293</td>\n",
       "      <td>0.730703</td>\n",
       "      <td>0.722574</td>\n",
       "      <td>0.003392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>127.176602</td>\n",
       "      <td>0.657280</td>\n",
       "      <td>0.023234</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100, '...</td>\n",
       "      <td>0.568273</td>\n",
       "      <td>0.609148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595492</td>\n",
       "      <td>0.593178</td>\n",
       "      <td>0.594913</td>\n",
       "      <td>0.593920</td>\n",
       "      <td>0.593249</td>\n",
       "      <td>0.594110</td>\n",
       "      <td>0.597505</td>\n",
       "      <td>0.600256</td>\n",
       "      <td>0.595599</td>\n",
       "      <td>0.002331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>183.508827</td>\n",
       "      <td>2.019694</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100, '...</td>\n",
       "      <td>0.570881</td>\n",
       "      <td>0.610511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596368</td>\n",
       "      <td>0.593787</td>\n",
       "      <td>0.595958</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.595098</td>\n",
       "      <td>0.595304</td>\n",
       "      <td>0.598921</td>\n",
       "      <td>0.601620</td>\n",
       "      <td>0.596822</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>244.027693</td>\n",
       "      <td>4.153268</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100, '...</td>\n",
       "      <td>0.573845</td>\n",
       "      <td>0.614277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598717</td>\n",
       "      <td>0.595456</td>\n",
       "      <td>0.597651</td>\n",
       "      <td>0.596914</td>\n",
       "      <td>0.597264</td>\n",
       "      <td>0.597888</td>\n",
       "      <td>0.600343</td>\n",
       "      <td>0.603150</td>\n",
       "      <td>0.598728</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.743908</td>\n",
       "      <td>0.310640</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 25, 'su...</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.503909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475232</td>\n",
       "      <td>0.475141</td>\n",
       "      <td>0.475220</td>\n",
       "      <td>0.473677</td>\n",
       "      <td>0.473581</td>\n",
       "      <td>0.473298</td>\n",
       "      <td>0.476865</td>\n",
       "      <td>0.476409</td>\n",
       "      <td>0.475355</td>\n",
       "      <td>0.001777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      35.026700      0.260215         0.020645        0.001842   \n",
       "1      48.980678      0.179243         0.021446        0.003313   \n",
       "2      63.139601      0.174975         0.020246        0.002188   \n",
       "3      65.704232      0.366242         0.021243        0.002603   \n",
       "4      93.308612      0.591235         0.022440        0.003995   \n",
       "5     122.811179      2.825839         0.023441        0.005317   \n",
       "6     127.176602      0.657280         0.023234        0.002898   \n",
       "7     183.508827      2.019694         0.024136        0.002884   \n",
       "8     244.027693      4.153268         0.025036        0.004423   \n",
       "9      36.743908      0.310640         0.021844        0.000709   \n",
       "\n",
       "  param_learning_rate param_n_estimators param_subsample  \\\n",
       "0                0.01                 25             0.6   \n",
       "1                0.01                 25             0.8   \n",
       "2                0.01                 25               1   \n",
       "3                0.01                 50             0.6   \n",
       "4                0.01                 50             0.8   \n",
       "5                0.01                 50               1   \n",
       "6                0.01                100             0.6   \n",
       "7                0.01                100             0.8   \n",
       "8                0.01                100               1   \n",
       "9                 0.1                 25             0.6   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.01, 'n_estimators': 25, 's...           0.793623   \n",
       "1  {'learning_rate': 0.01, 'n_estimators': 25, 's...           0.792276   \n",
       "2  {'learning_rate': 0.01, 'n_estimators': 25, 's...           0.793491   \n",
       "3  {'learning_rate': 0.01, 'n_estimators': 50, 's...           0.686398   \n",
       "4  {'learning_rate': 0.01, 'n_estimators': 50, 's...           0.687524   \n",
       "5  {'learning_rate': 0.01, 'n_estimators': 50, 's...           0.688819   \n",
       "6  {'learning_rate': 0.01, 'n_estimators': 100, '...           0.568273   \n",
       "7  {'learning_rate': 0.01, 'n_estimators': 100, '...           0.570881   \n",
       "8  {'learning_rate': 0.01, 'n_estimators': 100, '...           0.573845   \n",
       "9  {'learning_rate': 0.1, 'n_estimators': 25, 'su...           0.471503   \n",
       "\n",
       "   split1_test_score       ...         split2_train_score  split3_train_score  \\\n",
       "0           0.835415       ...                   0.829317            0.825115   \n",
       "1           0.834645       ...                   0.830259            0.826020   \n",
       "2           0.836605       ...                   0.830612            0.825974   \n",
       "3           0.729281       ...                   0.720222            0.716070   \n",
       "4           0.729157       ...                   0.720687            0.716899   \n",
       "5           0.731255       ...                   0.721694            0.718104   \n",
       "6           0.609148       ...                   0.595492            0.593178   \n",
       "7           0.610511       ...                   0.596368            0.593787   \n",
       "8           0.614277       ...                   0.598717            0.595456   \n",
       "9           0.503909       ...                   0.475232            0.475141   \n",
       "\n",
       "   split4_train_score  split5_train_score  split6_train_score  \\\n",
       "0            0.828734            0.827507            0.828922   \n",
       "1            0.829009            0.827749            0.829333   \n",
       "2            0.829575            0.828113            0.830659   \n",
       "3            0.718915            0.718778            0.718094   \n",
       "4            0.720208            0.719302            0.719525   \n",
       "5            0.720822            0.719624            0.721509   \n",
       "6            0.594913            0.593920            0.593249   \n",
       "7            0.595958            0.595801            0.595098   \n",
       "8            0.597651            0.596914            0.597264   \n",
       "9            0.475220            0.473677            0.473581   \n",
       "\n",
       "   split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0            0.828876            0.833301            0.841282   \n",
       "1            0.829420            0.833678            0.842273   \n",
       "2            0.830416            0.834267            0.842854   \n",
       "3            0.719638            0.723139            0.728912   \n",
       "4            0.719583            0.723224            0.729401   \n",
       "5            0.721375            0.724293            0.730703   \n",
       "6            0.594110            0.597505            0.600256   \n",
       "7            0.595304            0.598921            0.601620   \n",
       "8            0.597888            0.600343            0.603150   \n",
       "9            0.473298            0.476865            0.476409   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.830884         0.004457  \n",
       "1          0.831280         0.004438  \n",
       "2          0.831923         0.004495  \n",
       "3          0.720774         0.003519  \n",
       "4          0.721479         0.003415  \n",
       "5          0.722574         0.003392  \n",
       "6          0.595599         0.002331  \n",
       "7          0.596822         0.002392  \n",
       "8          0.598728         0.002334  \n",
       "9          0.475355         0.001777  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gardient Boosting Regression\n",
    "\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "grid = GridSearchCV(estimator = GradientBoostingRegressor(), param_grid = {'learning_rate':[0.01,0.1,0.5],'n_estimators':[25,50,100],'subsample':[0.6,0.8,1.0]}, scoring =mse, cv = 10, return_train_score=True).fit(X_train_preprocessed3, y_train)\n",
    "result = pd.DataFrame(grid.cv_results_)\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.793623</td>\n",
       "      <td>0.792276</td>\n",
       "      <td>0.793491</td>\n",
       "      <td>0.686398</td>\n",
       "      <td>0.687524</td>\n",
       "      <td>0.688819</td>\n",
       "      <td>0.568273</td>\n",
       "      <td>0.570881</td>\n",
       "      <td>0.573845</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.466046</td>\n",
       "      <td>0.471722</td>\n",
       "      <td>0.439986</td>\n",
       "      <td>0.439179</td>\n",
       "      <td>0.440732</td>\n",
       "      <td>0.424906</td>\n",
       "      <td>0.428418</td>\n",
       "      <td>0.428827</td>\n",
       "      <td>0.464373</td>\n",
       "      <td>0.458582</td>\n",
       "      <td>0.447771</td>\n",
       "      <td>0.473403</td>\n",
       "      <td>0.446506</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.470542</td>\n",
       "      <td>0.446906</td>\n",
       "      <td>0.440102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.835415</td>\n",
       "      <td>0.834645</td>\n",
       "      <td>0.836605</td>\n",
       "      <td>0.729281</td>\n",
       "      <td>0.729157</td>\n",
       "      <td>0.731255</td>\n",
       "      <td>0.609148</td>\n",
       "      <td>0.610511</td>\n",
       "      <td>0.614277</td>\n",
       "      <td>0.503909</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>0.507161</td>\n",
       "      <td>0.476449</td>\n",
       "      <td>0.477934</td>\n",
       "      <td>0.477874</td>\n",
       "      <td>0.454803</td>\n",
       "      <td>0.462285</td>\n",
       "      <td>0.458377</td>\n",
       "      <td>0.478686</td>\n",
       "      <td>0.476451</td>\n",
       "      <td>0.479785</td>\n",
       "      <td>0.485087</td>\n",
       "      <td>0.465813</td>\n",
       "      <td>0.473234</td>\n",
       "      <td>0.471541</td>\n",
       "      <td>0.453353</td>\n",
       "      <td>0.467965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.847920</td>\n",
       "      <td>0.848725</td>\n",
       "      <td>0.850004</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>0.742185</td>\n",
       "      <td>0.743636</td>\n",
       "      <td>0.615579</td>\n",
       "      <td>0.617340</td>\n",
       "      <td>0.619723</td>\n",
       "      <td>0.492954</td>\n",
       "      <td>0.500463</td>\n",
       "      <td>0.504648</td>\n",
       "      <td>0.459951</td>\n",
       "      <td>0.464143</td>\n",
       "      <td>0.468436</td>\n",
       "      <td>0.446613</td>\n",
       "      <td>0.447050</td>\n",
       "      <td>0.456178</td>\n",
       "      <td>0.473885</td>\n",
       "      <td>0.452756</td>\n",
       "      <td>0.459381</td>\n",
       "      <td>0.478022</td>\n",
       "      <td>0.469962</td>\n",
       "      <td>0.455245</td>\n",
       "      <td>0.472078</td>\n",
       "      <td>0.456359</td>\n",
       "      <td>0.454313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.896416</td>\n",
       "      <td>0.897813</td>\n",
       "      <td>0.897684</td>\n",
       "      <td>0.784217</td>\n",
       "      <td>0.785097</td>\n",
       "      <td>0.785578</td>\n",
       "      <td>0.650875</td>\n",
       "      <td>0.651913</td>\n",
       "      <td>0.654454</td>\n",
       "      <td>0.520262</td>\n",
       "      <td>0.518280</td>\n",
       "      <td>0.516913</td>\n",
       "      <td>0.476676</td>\n",
       "      <td>0.474561</td>\n",
       "      <td>0.473313</td>\n",
       "      <td>0.449875</td>\n",
       "      <td>0.449792</td>\n",
       "      <td>0.453847</td>\n",
       "      <td>0.472001</td>\n",
       "      <td>0.454928</td>\n",
       "      <td>0.466389</td>\n",
       "      <td>0.459726</td>\n",
       "      <td>0.469316</td>\n",
       "      <td>0.455810</td>\n",
       "      <td>0.448189</td>\n",
       "      <td>0.452387</td>\n",
       "      <td>0.462176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.859655</td>\n",
       "      <td>0.859753</td>\n",
       "      <td>0.860523</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.746512</td>\n",
       "      <td>0.748515</td>\n",
       "      <td>0.616295</td>\n",
       "      <td>0.618751</td>\n",
       "      <td>0.621876</td>\n",
       "      <td>0.493690</td>\n",
       "      <td>0.494692</td>\n",
       "      <td>0.501770</td>\n",
       "      <td>0.456920</td>\n",
       "      <td>0.460959</td>\n",
       "      <td>0.464720</td>\n",
       "      <td>0.435578</td>\n",
       "      <td>0.439475</td>\n",
       "      <td>0.445416</td>\n",
       "      <td>0.453857</td>\n",
       "      <td>0.459239</td>\n",
       "      <td>0.460773</td>\n",
       "      <td>0.447096</td>\n",
       "      <td>0.453004</td>\n",
       "      <td>0.454524</td>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.448486</td>\n",
       "      <td>0.449464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>0.872369</td>\n",
       "      <td>0.873130</td>\n",
       "      <td>0.872942</td>\n",
       "      <td>0.755264</td>\n",
       "      <td>0.756830</td>\n",
       "      <td>0.758541</td>\n",
       "      <td>0.626036</td>\n",
       "      <td>0.627068</td>\n",
       "      <td>0.631284</td>\n",
       "      <td>0.503152</td>\n",
       "      <td>0.504979</td>\n",
       "      <td>0.511015</td>\n",
       "      <td>0.469860</td>\n",
       "      <td>0.470529</td>\n",
       "      <td>0.475059</td>\n",
       "      <td>0.453268</td>\n",
       "      <td>0.454408</td>\n",
       "      <td>0.457971</td>\n",
       "      <td>0.476461</td>\n",
       "      <td>0.465811</td>\n",
       "      <td>0.451288</td>\n",
       "      <td>0.480777</td>\n",
       "      <td>0.465493</td>\n",
       "      <td>0.447482</td>\n",
       "      <td>0.470592</td>\n",
       "      <td>0.478574</td>\n",
       "      <td>0.442454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>0.852670</td>\n",
       "      <td>0.853809</td>\n",
       "      <td>0.854786</td>\n",
       "      <td>0.743823</td>\n",
       "      <td>0.744769</td>\n",
       "      <td>0.749193</td>\n",
       "      <td>0.621840</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.631811</td>\n",
       "      <td>0.510018</td>\n",
       "      <td>0.516876</td>\n",
       "      <td>0.518977</td>\n",
       "      <td>0.479168</td>\n",
       "      <td>0.476716</td>\n",
       "      <td>0.486852</td>\n",
       "      <td>0.458387</td>\n",
       "      <td>0.454086</td>\n",
       "      <td>0.468980</td>\n",
       "      <td>0.472478</td>\n",
       "      <td>0.478436</td>\n",
       "      <td>0.476011</td>\n",
       "      <td>0.478438</td>\n",
       "      <td>0.479554</td>\n",
       "      <td>0.473880</td>\n",
       "      <td>0.467711</td>\n",
       "      <td>0.478800</td>\n",
       "      <td>0.467006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>0.859224</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.860192</td>\n",
       "      <td>0.752846</td>\n",
       "      <td>0.754083</td>\n",
       "      <td>0.755434</td>\n",
       "      <td>0.630985</td>\n",
       "      <td>0.634607</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.515324</td>\n",
       "      <td>0.518299</td>\n",
       "      <td>0.518706</td>\n",
       "      <td>0.477123</td>\n",
       "      <td>0.483702</td>\n",
       "      <td>0.482636</td>\n",
       "      <td>0.459560</td>\n",
       "      <td>0.467198</td>\n",
       "      <td>0.466510</td>\n",
       "      <td>0.485331</td>\n",
       "      <td>0.488447</td>\n",
       "      <td>0.461441</td>\n",
       "      <td>0.481021</td>\n",
       "      <td>0.457857</td>\n",
       "      <td>0.461614</td>\n",
       "      <td>0.478045</td>\n",
       "      <td>0.472765</td>\n",
       "      <td>0.460446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>0.811521</td>\n",
       "      <td>0.812362</td>\n",
       "      <td>0.813067</td>\n",
       "      <td>0.709048</td>\n",
       "      <td>0.708505</td>\n",
       "      <td>0.711169</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.592824</td>\n",
       "      <td>0.595574</td>\n",
       "      <td>0.482824</td>\n",
       "      <td>0.479048</td>\n",
       "      <td>0.488607</td>\n",
       "      <td>0.447666</td>\n",
       "      <td>0.452520</td>\n",
       "      <td>0.448457</td>\n",
       "      <td>0.424557</td>\n",
       "      <td>0.426213</td>\n",
       "      <td>0.433451</td>\n",
       "      <td>0.442001</td>\n",
       "      <td>0.439983</td>\n",
       "      <td>0.445243</td>\n",
       "      <td>0.461619</td>\n",
       "      <td>0.441126</td>\n",
       "      <td>0.440186</td>\n",
       "      <td>0.440419</td>\n",
       "      <td>0.461486</td>\n",
       "      <td>0.433539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>0.722943</td>\n",
       "      <td>0.723347</td>\n",
       "      <td>0.724227</td>\n",
       "      <td>0.632479</td>\n",
       "      <td>0.633188</td>\n",
       "      <td>0.635479</td>\n",
       "      <td>0.536907</td>\n",
       "      <td>0.540086</td>\n",
       "      <td>0.542894</td>\n",
       "      <td>0.459660</td>\n",
       "      <td>0.467791</td>\n",
       "      <td>0.465871</td>\n",
       "      <td>0.436844</td>\n",
       "      <td>0.439758</td>\n",
       "      <td>0.441451</td>\n",
       "      <td>0.420650</td>\n",
       "      <td>0.418003</td>\n",
       "      <td>0.424664</td>\n",
       "      <td>0.437044</td>\n",
       "      <td>0.426602</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.437770</td>\n",
       "      <td>0.431228</td>\n",
       "      <td>0.429673</td>\n",
       "      <td>0.426837</td>\n",
       "      <td>0.427483</td>\n",
       "      <td>0.425432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27\n",
       "split0_test_score  0.793623  0.792276  0.793491  0.686398  0.687524  0.688819  0.568273  0.570881  0.573845  0.471503  0.466046  0.471722  0.439986  0.439179  0.440732  0.424906  0.428418  0.428827  0.464373  0.458582  0.447771  0.473403  0.446506  0.441341  0.470542  0.446906  0.440102\n",
       "split1_test_score  0.835415  0.834645  0.836605  0.729281  0.729157  0.731255  0.609148  0.610511  0.614277  0.503909  0.506826  0.507161  0.476449  0.477934  0.477874  0.454803  0.462285  0.458377  0.478686  0.476451  0.479785  0.485087  0.465813  0.473234  0.471541  0.453353  0.467965\n",
       "split2_test_score  0.847920  0.848725  0.850004  0.740950  0.742185  0.743636  0.615579  0.617340  0.619723  0.492954  0.500463  0.504648  0.459951  0.464143  0.468436  0.446613  0.447050  0.456178  0.473885  0.452756  0.459381  0.478022  0.469962  0.455245  0.472078  0.456359  0.454313\n",
       "split3_test_score  0.896416  0.897813  0.897684  0.784217  0.785097  0.785578  0.650875  0.651913  0.654454  0.520262  0.518280  0.516913  0.476676  0.474561  0.473313  0.449875  0.449792  0.453847  0.472001  0.454928  0.466389  0.459726  0.469316  0.455810  0.448189  0.452387  0.462176\n",
       "split4_test_score  0.859655  0.859753  0.860523  0.744700  0.746512  0.748515  0.616295  0.618751  0.621876  0.493690  0.494692  0.501770  0.456920  0.460959  0.464720  0.435578  0.439475  0.445416  0.453857  0.459239  0.460773  0.447096  0.453004  0.454524  0.462799  0.448486  0.449464\n",
       "split5_test_score  0.872369  0.873130  0.872942  0.755264  0.756830  0.758541  0.626036  0.627068  0.631284  0.503152  0.504979  0.511015  0.469860  0.470529  0.475059  0.453268  0.454408  0.457971  0.476461  0.465811  0.451288  0.480777  0.465493  0.447482  0.470592  0.478574  0.442454\n",
       "split6_test_score  0.852670  0.853809  0.854786  0.743823  0.744769  0.749193  0.621840  0.625806  0.631811  0.510018  0.516876  0.518977  0.479168  0.476716  0.486852  0.458387  0.454086  0.468980  0.472478  0.478436  0.476011  0.478438  0.479554  0.473880  0.467711  0.478800  0.467006\n",
       "split7_test_score  0.859224  0.859678  0.860192  0.752846  0.754083  0.755434  0.630985  0.634607  0.636000  0.515324  0.518299  0.518706  0.477123  0.483702  0.482636  0.459560  0.467198  0.466510  0.485331  0.488447  0.461441  0.481021  0.457857  0.461614  0.478045  0.472765  0.460446\n",
       "split8_test_score  0.811521  0.812362  0.813067  0.709048  0.708505  0.711169  0.588915  0.592824  0.595574  0.482824  0.479048  0.488607  0.447666  0.452520  0.448457  0.424557  0.426213  0.433451  0.442001  0.439983  0.445243  0.461619  0.441126  0.440186  0.440419  0.461486  0.433539\n",
       "split9_test_score  0.722943  0.723347  0.724227  0.632479  0.633188  0.635479  0.536907  0.540086  0.542894  0.459660  0.467791  0.465871  0.436844  0.439758  0.441451  0.420650  0.418003  0.424664  0.437044  0.426602  0.444882  0.437770  0.431228  0.429673  0.426837  0.427483  0.425432"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_filtered2 = result[[\"split0_test_score\",\"split1_test_score\",\"split2_test_score\",\"split3_test_score\",\"split4_test_score\",\"split5_test_score\",\"split6_test_score\",\"split7_test_score\",\"split8_test_score\",\"split9_test_score\"]]\n",
    "result_filtered3_gb = np.transpose(result_filtered2)\n",
    "result_filtered3_gb.columns = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27']\n",
    "result_filtered3_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.026700</td>\n",
       "      <td>0.260215</td>\n",
       "      <td>0.020645</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 25, 's...</td>\n",
       "      <td>0.793623</td>\n",
       "      <td>0.835415</td>\n",
       "      <td>0.847920</td>\n",
       "      <td>0.896416</td>\n",
       "      <td>0.859655</td>\n",
       "      <td>0.872369</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>0.859224</td>\n",
       "      <td>0.811521</td>\n",
       "      <td>0.722943</td>\n",
       "      <td>0.835176</td>\n",
       "      <td>0.046543</td>\n",
       "      <td>3</td>\n",
       "      <td>0.835802</td>\n",
       "      <td>0.829987</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.825115</td>\n",
       "      <td>0.828734</td>\n",
       "      <td>0.827507</td>\n",
       "      <td>0.828922</td>\n",
       "      <td>0.828876</td>\n",
       "      <td>0.833301</td>\n",
       "      <td>0.841282</td>\n",
       "      <td>0.830884</td>\n",
       "      <td>0.004457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.980678</td>\n",
       "      <td>0.179243</td>\n",
       "      <td>0.021446</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 25, 's...</td>\n",
       "      <td>0.792276</td>\n",
       "      <td>0.834645</td>\n",
       "      <td>0.848725</td>\n",
       "      <td>0.897813</td>\n",
       "      <td>0.859753</td>\n",
       "      <td>0.873130</td>\n",
       "      <td>0.853809</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.812362</td>\n",
       "      <td>0.723347</td>\n",
       "      <td>0.835554</td>\n",
       "      <td>0.046866</td>\n",
       "      <td>2</td>\n",
       "      <td>0.835145</td>\n",
       "      <td>0.829911</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.826020</td>\n",
       "      <td>0.829009</td>\n",
       "      <td>0.827749</td>\n",
       "      <td>0.829333</td>\n",
       "      <td>0.829420</td>\n",
       "      <td>0.833678</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.831280</td>\n",
       "      <td>0.004438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.139601</td>\n",
       "      <td>0.174975</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 25, 's...</td>\n",
       "      <td>0.793491</td>\n",
       "      <td>0.836605</td>\n",
       "      <td>0.850004</td>\n",
       "      <td>0.897684</td>\n",
       "      <td>0.860523</td>\n",
       "      <td>0.872942</td>\n",
       "      <td>0.854786</td>\n",
       "      <td>0.860192</td>\n",
       "      <td>0.813067</td>\n",
       "      <td>0.724227</td>\n",
       "      <td>0.836352</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835808</td>\n",
       "      <td>0.830953</td>\n",
       "      <td>0.830612</td>\n",
       "      <td>0.825974</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>0.828113</td>\n",
       "      <td>0.830659</td>\n",
       "      <td>0.830416</td>\n",
       "      <td>0.834267</td>\n",
       "      <td>0.842854</td>\n",
       "      <td>0.831923</td>\n",
       "      <td>0.004495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.704232</td>\n",
       "      <td>0.366242</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 50, 's...</td>\n",
       "      <td>0.686398</td>\n",
       "      <td>0.729281</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>0.784217</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.755264</td>\n",
       "      <td>0.743823</td>\n",
       "      <td>0.752846</td>\n",
       "      <td>0.709048</td>\n",
       "      <td>0.632479</td>\n",
       "      <td>0.727901</td>\n",
       "      <td>0.040539</td>\n",
       "      <td>6</td>\n",
       "      <td>0.724301</td>\n",
       "      <td>0.719675</td>\n",
       "      <td>0.720222</td>\n",
       "      <td>0.716070</td>\n",
       "      <td>0.718915</td>\n",
       "      <td>0.718778</td>\n",
       "      <td>0.718094</td>\n",
       "      <td>0.719638</td>\n",
       "      <td>0.723139</td>\n",
       "      <td>0.728912</td>\n",
       "      <td>0.720774</td>\n",
       "      <td>0.003519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.308612</td>\n",
       "      <td>0.591235</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 50, 's...</td>\n",
       "      <td>0.687524</td>\n",
       "      <td>0.729157</td>\n",
       "      <td>0.742185</td>\n",
       "      <td>0.785097</td>\n",
       "      <td>0.746512</td>\n",
       "      <td>0.756830</td>\n",
       "      <td>0.744769</td>\n",
       "      <td>0.754083</td>\n",
       "      <td>0.708505</td>\n",
       "      <td>0.633188</td>\n",
       "      <td>0.728785</td>\n",
       "      <td>0.040743</td>\n",
       "      <td>5</td>\n",
       "      <td>0.725322</td>\n",
       "      <td>0.720638</td>\n",
       "      <td>0.720687</td>\n",
       "      <td>0.716899</td>\n",
       "      <td>0.720208</td>\n",
       "      <td>0.719302</td>\n",
       "      <td>0.719525</td>\n",
       "      <td>0.719583</td>\n",
       "      <td>0.723224</td>\n",
       "      <td>0.729401</td>\n",
       "      <td>0.721479</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>122.811179</td>\n",
       "      <td>2.825839</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 50, 's...</td>\n",
       "      <td>0.688819</td>\n",
       "      <td>0.731255</td>\n",
       "      <td>0.743636</td>\n",
       "      <td>0.785578</td>\n",
       "      <td>0.748515</td>\n",
       "      <td>0.758541</td>\n",
       "      <td>0.749193</td>\n",
       "      <td>0.755434</td>\n",
       "      <td>0.711169</td>\n",
       "      <td>0.635479</td>\n",
       "      <td>0.730762</td>\n",
       "      <td>0.040532</td>\n",
       "      <td>4</td>\n",
       "      <td>0.725792</td>\n",
       "      <td>0.721824</td>\n",
       "      <td>0.721694</td>\n",
       "      <td>0.718104</td>\n",
       "      <td>0.720822</td>\n",
       "      <td>0.719624</td>\n",
       "      <td>0.721509</td>\n",
       "      <td>0.721375</td>\n",
       "      <td>0.724293</td>\n",
       "      <td>0.730703</td>\n",
       "      <td>0.722574</td>\n",
       "      <td>0.003392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>127.176602</td>\n",
       "      <td>0.657280</td>\n",
       "      <td>0.023234</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100, '...</td>\n",
       "      <td>0.568273</td>\n",
       "      <td>0.609148</td>\n",
       "      <td>0.615579</td>\n",
       "      <td>0.650875</td>\n",
       "      <td>0.616295</td>\n",
       "      <td>0.626036</td>\n",
       "      <td>0.621840</td>\n",
       "      <td>0.630985</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.536907</td>\n",
       "      <td>0.606485</td>\n",
       "      <td>0.031599</td>\n",
       "      <td>9</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>0.594475</td>\n",
       "      <td>0.595492</td>\n",
       "      <td>0.593178</td>\n",
       "      <td>0.594913</td>\n",
       "      <td>0.593920</td>\n",
       "      <td>0.593249</td>\n",
       "      <td>0.594110</td>\n",
       "      <td>0.597505</td>\n",
       "      <td>0.600256</td>\n",
       "      <td>0.595599</td>\n",
       "      <td>0.002331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>183.508827</td>\n",
       "      <td>2.019694</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100, '...</td>\n",
       "      <td>0.570881</td>\n",
       "      <td>0.610511</td>\n",
       "      <td>0.617340</td>\n",
       "      <td>0.651913</td>\n",
       "      <td>0.618751</td>\n",
       "      <td>0.627068</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.634607</td>\n",
       "      <td>0.592824</td>\n",
       "      <td>0.540086</td>\n",
       "      <td>0.608979</td>\n",
       "      <td>0.031204</td>\n",
       "      <td>8</td>\n",
       "      <td>0.600118</td>\n",
       "      <td>0.595250</td>\n",
       "      <td>0.596368</td>\n",
       "      <td>0.593787</td>\n",
       "      <td>0.595958</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.595098</td>\n",
       "      <td>0.595304</td>\n",
       "      <td>0.598921</td>\n",
       "      <td>0.601620</td>\n",
       "      <td>0.596822</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>244.027693</td>\n",
       "      <td>4.153268</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100, '...</td>\n",
       "      <td>0.573845</td>\n",
       "      <td>0.614277</td>\n",
       "      <td>0.619723</td>\n",
       "      <td>0.654454</td>\n",
       "      <td>0.621876</td>\n",
       "      <td>0.631284</td>\n",
       "      <td>0.631811</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.595574</td>\n",
       "      <td>0.542894</td>\n",
       "      <td>0.612174</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>7</td>\n",
       "      <td>0.602331</td>\n",
       "      <td>0.597571</td>\n",
       "      <td>0.598717</td>\n",
       "      <td>0.595456</td>\n",
       "      <td>0.597651</td>\n",
       "      <td>0.596914</td>\n",
       "      <td>0.597264</td>\n",
       "      <td>0.597888</td>\n",
       "      <td>0.600343</td>\n",
       "      <td>0.603150</td>\n",
       "      <td>0.598728</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.743908</td>\n",
       "      <td>0.310640</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 25, 'su...</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.503909</td>\n",
       "      <td>0.492954</td>\n",
       "      <td>0.520262</td>\n",
       "      <td>0.493690</td>\n",
       "      <td>0.503152</td>\n",
       "      <td>0.510018</td>\n",
       "      <td>0.515324</td>\n",
       "      <td>0.482824</td>\n",
       "      <td>0.459660</td>\n",
       "      <td>0.495330</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>12</td>\n",
       "      <td>0.479521</td>\n",
       "      <td>0.474608</td>\n",
       "      <td>0.475232</td>\n",
       "      <td>0.475141</td>\n",
       "      <td>0.475220</td>\n",
       "      <td>0.473677</td>\n",
       "      <td>0.473581</td>\n",
       "      <td>0.473298</td>\n",
       "      <td>0.476865</td>\n",
       "      <td>0.476409</td>\n",
       "      <td>0.475355</td>\n",
       "      <td>0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51.146483</td>\n",
       "      <td>0.209953</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 25, 'su...</td>\n",
       "      <td>0.466046</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>0.500463</td>\n",
       "      <td>0.518280</td>\n",
       "      <td>0.494692</td>\n",
       "      <td>0.504979</td>\n",
       "      <td>0.516876</td>\n",
       "      <td>0.518299</td>\n",
       "      <td>0.479048</td>\n",
       "      <td>0.467791</td>\n",
       "      <td>0.497330</td>\n",
       "      <td>0.019004</td>\n",
       "      <td>11</td>\n",
       "      <td>0.477325</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.478112</td>\n",
       "      <td>0.475059</td>\n",
       "      <td>0.475316</td>\n",
       "      <td>0.473738</td>\n",
       "      <td>0.475928</td>\n",
       "      <td>0.473985</td>\n",
       "      <td>0.475087</td>\n",
       "      <td>0.476761</td>\n",
       "      <td>0.475428</td>\n",
       "      <td>0.001551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66.123022</td>\n",
       "      <td>0.351047</td>\n",
       "      <td>0.020448</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 25, 'su...</td>\n",
       "      <td>0.471722</td>\n",
       "      <td>0.507161</td>\n",
       "      <td>0.504648</td>\n",
       "      <td>0.516913</td>\n",
       "      <td>0.501770</td>\n",
       "      <td>0.511015</td>\n",
       "      <td>0.518977</td>\n",
       "      <td>0.518706</td>\n",
       "      <td>0.488607</td>\n",
       "      <td>0.465871</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.018124</td>\n",
       "      <td>10</td>\n",
       "      <td>0.477839</td>\n",
       "      <td>0.472340</td>\n",
       "      <td>0.476444</td>\n",
       "      <td>0.474636</td>\n",
       "      <td>0.476254</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.475867</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.477477</td>\n",
       "      <td>0.477282</td>\n",
       "      <td>0.475737</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>71.318518</td>\n",
       "      <td>0.339837</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50, 'su...</td>\n",
       "      <td>0.439986</td>\n",
       "      <td>0.476449</td>\n",
       "      <td>0.459951</td>\n",
       "      <td>0.476676</td>\n",
       "      <td>0.456920</td>\n",
       "      <td>0.469860</td>\n",
       "      <td>0.479168</td>\n",
       "      <td>0.477123</td>\n",
       "      <td>0.447666</td>\n",
       "      <td>0.436844</td>\n",
       "      <td>0.462064</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>17</td>\n",
       "      <td>0.432302</td>\n",
       "      <td>0.428650</td>\n",
       "      <td>0.427210</td>\n",
       "      <td>0.429360</td>\n",
       "      <td>0.429112</td>\n",
       "      <td>0.430893</td>\n",
       "      <td>0.428568</td>\n",
       "      <td>0.428492</td>\n",
       "      <td>0.433454</td>\n",
       "      <td>0.429595</td>\n",
       "      <td>0.429764</td>\n",
       "      <td>0.001810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.970703</td>\n",
       "      <td>0.817812</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50, 'su...</td>\n",
       "      <td>0.439179</td>\n",
       "      <td>0.477934</td>\n",
       "      <td>0.464143</td>\n",
       "      <td>0.474561</td>\n",
       "      <td>0.460959</td>\n",
       "      <td>0.470529</td>\n",
       "      <td>0.476716</td>\n",
       "      <td>0.483702</td>\n",
       "      <td>0.452520</td>\n",
       "      <td>0.439758</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>16</td>\n",
       "      <td>0.433044</td>\n",
       "      <td>0.429475</td>\n",
       "      <td>0.428821</td>\n",
       "      <td>0.429363</td>\n",
       "      <td>0.429462</td>\n",
       "      <td>0.427397</td>\n",
       "      <td>0.430502</td>\n",
       "      <td>0.426507</td>\n",
       "      <td>0.431383</td>\n",
       "      <td>0.431163</td>\n",
       "      <td>0.429712</td>\n",
       "      <td>0.001825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>133.224521</td>\n",
       "      <td>0.474954</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50, 'su...</td>\n",
       "      <td>0.440732</td>\n",
       "      <td>0.477874</td>\n",
       "      <td>0.468436</td>\n",
       "      <td>0.473313</td>\n",
       "      <td>0.464720</td>\n",
       "      <td>0.475059</td>\n",
       "      <td>0.486852</td>\n",
       "      <td>0.482636</td>\n",
       "      <td>0.448457</td>\n",
       "      <td>0.441451</td>\n",
       "      <td>0.465953</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>14</td>\n",
       "      <td>0.431530</td>\n",
       "      <td>0.427822</td>\n",
       "      <td>0.430463</td>\n",
       "      <td>0.430221</td>\n",
       "      <td>0.431784</td>\n",
       "      <td>0.430338</td>\n",
       "      <td>0.430546</td>\n",
       "      <td>0.430617</td>\n",
       "      <td>0.433477</td>\n",
       "      <td>0.431479</td>\n",
       "      <td>0.430828</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>141.635818</td>\n",
       "      <td>0.927409</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100, 's...</td>\n",
       "      <td>0.424906</td>\n",
       "      <td>0.454803</td>\n",
       "      <td>0.446613</td>\n",
       "      <td>0.449875</td>\n",
       "      <td>0.435578</td>\n",
       "      <td>0.453268</td>\n",
       "      <td>0.458387</td>\n",
       "      <td>0.459560</td>\n",
       "      <td>0.424557</td>\n",
       "      <td>0.420650</td>\n",
       "      <td>0.442820</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>27</td>\n",
       "      <td>0.396716</td>\n",
       "      <td>0.392756</td>\n",
       "      <td>0.393148</td>\n",
       "      <td>0.394692</td>\n",
       "      <td>0.394976</td>\n",
       "      <td>0.394087</td>\n",
       "      <td>0.394239</td>\n",
       "      <td>0.392806</td>\n",
       "      <td>0.396626</td>\n",
       "      <td>0.393133</td>\n",
       "      <td>0.394318</td>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>203.647532</td>\n",
       "      <td>0.874588</td>\n",
       "      <td>0.024833</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100, 's...</td>\n",
       "      <td>0.428418</td>\n",
       "      <td>0.462285</td>\n",
       "      <td>0.447050</td>\n",
       "      <td>0.449792</td>\n",
       "      <td>0.439475</td>\n",
       "      <td>0.454408</td>\n",
       "      <td>0.454086</td>\n",
       "      <td>0.467198</td>\n",
       "      <td>0.426213</td>\n",
       "      <td>0.418003</td>\n",
       "      <td>0.444693</td>\n",
       "      <td>0.015415</td>\n",
       "      <td>26</td>\n",
       "      <td>0.398491</td>\n",
       "      <td>0.390450</td>\n",
       "      <td>0.394292</td>\n",
       "      <td>0.394044</td>\n",
       "      <td>0.395993</td>\n",
       "      <td>0.394809</td>\n",
       "      <td>0.392360</td>\n",
       "      <td>0.393985</td>\n",
       "      <td>0.393613</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.394334</td>\n",
       "      <td>0.002023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>268.515495</td>\n",
       "      <td>2.265846</td>\n",
       "      <td>0.025522</td>\n",
       "      <td>0.004090</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100, 's...</td>\n",
       "      <td>0.428827</td>\n",
       "      <td>0.458377</td>\n",
       "      <td>0.456178</td>\n",
       "      <td>0.453847</td>\n",
       "      <td>0.445416</td>\n",
       "      <td>0.457971</td>\n",
       "      <td>0.468980</td>\n",
       "      <td>0.466510</td>\n",
       "      <td>0.433451</td>\n",
       "      <td>0.424664</td>\n",
       "      <td>0.449422</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>25</td>\n",
       "      <td>0.399886</td>\n",
       "      <td>0.396361</td>\n",
       "      <td>0.399290</td>\n",
       "      <td>0.398690</td>\n",
       "      <td>0.401677</td>\n",
       "      <td>0.400767</td>\n",
       "      <td>0.399391</td>\n",
       "      <td>0.400549</td>\n",
       "      <td>0.402911</td>\n",
       "      <td>0.401658</td>\n",
       "      <td>0.400118</td>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39.037271</td>\n",
       "      <td>0.148001</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 25, 'su...</td>\n",
       "      <td>0.464373</td>\n",
       "      <td>0.478686</td>\n",
       "      <td>0.473885</td>\n",
       "      <td>0.472001</td>\n",
       "      <td>0.453857</td>\n",
       "      <td>0.476461</td>\n",
       "      <td>0.472478</td>\n",
       "      <td>0.485331</td>\n",
       "      <td>0.442001</td>\n",
       "      <td>0.437044</td>\n",
       "      <td>0.465612</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>15</td>\n",
       "      <td>0.409413</td>\n",
       "      <td>0.401205</td>\n",
       "      <td>0.409182</td>\n",
       "      <td>0.405584</td>\n",
       "      <td>0.408256</td>\n",
       "      <td>0.402039</td>\n",
       "      <td>0.409532</td>\n",
       "      <td>0.403353</td>\n",
       "      <td>0.408962</td>\n",
       "      <td>0.410206</td>\n",
       "      <td>0.406773</td>\n",
       "      <td>0.003251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>54.843581</td>\n",
       "      <td>0.254365</td>\n",
       "      <td>0.021642</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 25, 'su...</td>\n",
       "      <td>0.458582</td>\n",
       "      <td>0.476451</td>\n",
       "      <td>0.452756</td>\n",
       "      <td>0.454928</td>\n",
       "      <td>0.459239</td>\n",
       "      <td>0.465811</td>\n",
       "      <td>0.478436</td>\n",
       "      <td>0.488447</td>\n",
       "      <td>0.439983</td>\n",
       "      <td>0.426602</td>\n",
       "      <td>0.460124</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>19</td>\n",
       "      <td>0.395318</td>\n",
       "      <td>0.396745</td>\n",
       "      <td>0.399573</td>\n",
       "      <td>0.395745</td>\n",
       "      <td>0.404031</td>\n",
       "      <td>0.398760</td>\n",
       "      <td>0.397987</td>\n",
       "      <td>0.401996</td>\n",
       "      <td>0.398767</td>\n",
       "      <td>0.404609</td>\n",
       "      <td>0.399353</td>\n",
       "      <td>0.003085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>70.912507</td>\n",
       "      <td>0.331270</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 25, 'su...</td>\n",
       "      <td>0.447771</td>\n",
       "      <td>0.479785</td>\n",
       "      <td>0.459381</td>\n",
       "      <td>0.466389</td>\n",
       "      <td>0.460773</td>\n",
       "      <td>0.451288</td>\n",
       "      <td>0.476011</td>\n",
       "      <td>0.461441</td>\n",
       "      <td>0.445243</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.459296</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>20</td>\n",
       "      <td>0.400404</td>\n",
       "      <td>0.398188</td>\n",
       "      <td>0.400619</td>\n",
       "      <td>0.399534</td>\n",
       "      <td>0.398079</td>\n",
       "      <td>0.400212</td>\n",
       "      <td>0.395548</td>\n",
       "      <td>0.395555</td>\n",
       "      <td>0.403170</td>\n",
       "      <td>0.400795</td>\n",
       "      <td>0.399210</td>\n",
       "      <td>0.002276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>74.172988</td>\n",
       "      <td>0.228979</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50, 'su...</td>\n",
       "      <td>0.473403</td>\n",
       "      <td>0.485087</td>\n",
       "      <td>0.478022</td>\n",
       "      <td>0.459726</td>\n",
       "      <td>0.447096</td>\n",
       "      <td>0.480777</td>\n",
       "      <td>0.478438</td>\n",
       "      <td>0.481021</td>\n",
       "      <td>0.461619</td>\n",
       "      <td>0.437770</td>\n",
       "      <td>0.468296</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>13</td>\n",
       "      <td>0.376583</td>\n",
       "      <td>0.367501</td>\n",
       "      <td>0.370057</td>\n",
       "      <td>0.366428</td>\n",
       "      <td>0.367339</td>\n",
       "      <td>0.370303</td>\n",
       "      <td>0.366576</td>\n",
       "      <td>0.366766</td>\n",
       "      <td>0.372662</td>\n",
       "      <td>0.372880</td>\n",
       "      <td>0.369709</td>\n",
       "      <td>0.003259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>106.211889</td>\n",
       "      <td>0.608226</td>\n",
       "      <td>0.023228</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50, 'su...</td>\n",
       "      <td>0.446506</td>\n",
       "      <td>0.465813</td>\n",
       "      <td>0.469962</td>\n",
       "      <td>0.469316</td>\n",
       "      <td>0.453004</td>\n",
       "      <td>0.465493</td>\n",
       "      <td>0.479554</td>\n",
       "      <td>0.457857</td>\n",
       "      <td>0.441126</td>\n",
       "      <td>0.431228</td>\n",
       "      <td>0.457986</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>21</td>\n",
       "      <td>0.363619</td>\n",
       "      <td>0.359818</td>\n",
       "      <td>0.358182</td>\n",
       "      <td>0.361736</td>\n",
       "      <td>0.363987</td>\n",
       "      <td>0.364170</td>\n",
       "      <td>0.359645</td>\n",
       "      <td>0.368082</td>\n",
       "      <td>0.361589</td>\n",
       "      <td>0.370872</td>\n",
       "      <td>0.363170</td>\n",
       "      <td>0.003720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>138.797165</td>\n",
       "      <td>0.921752</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50, 'su...</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.473234</td>\n",
       "      <td>0.455245</td>\n",
       "      <td>0.455810</td>\n",
       "      <td>0.454524</td>\n",
       "      <td>0.447482</td>\n",
       "      <td>0.473880</td>\n",
       "      <td>0.461614</td>\n",
       "      <td>0.440186</td>\n",
       "      <td>0.429673</td>\n",
       "      <td>0.453299</td>\n",
       "      <td>0.013449</td>\n",
       "      <td>23</td>\n",
       "      <td>0.364249</td>\n",
       "      <td>0.363261</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.366069</td>\n",
       "      <td>0.365426</td>\n",
       "      <td>0.363936</td>\n",
       "      <td>0.365985</td>\n",
       "      <td>0.365002</td>\n",
       "      <td>0.368040</td>\n",
       "      <td>0.367239</td>\n",
       "      <td>0.365831</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>144.850668</td>\n",
       "      <td>0.594397</td>\n",
       "      <td>0.023840</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100, 's...</td>\n",
       "      <td>0.470542</td>\n",
       "      <td>0.471541</td>\n",
       "      <td>0.472078</td>\n",
       "      <td>0.448189</td>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.470592</td>\n",
       "      <td>0.467711</td>\n",
       "      <td>0.478045</td>\n",
       "      <td>0.440419</td>\n",
       "      <td>0.426837</td>\n",
       "      <td>0.460875</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>18</td>\n",
       "      <td>0.323526</td>\n",
       "      <td>0.322026</td>\n",
       "      <td>0.319297</td>\n",
       "      <td>0.327097</td>\n",
       "      <td>0.323586</td>\n",
       "      <td>0.328347</td>\n",
       "      <td>0.320852</td>\n",
       "      <td>0.330037</td>\n",
       "      <td>0.325919</td>\n",
       "      <td>0.325612</td>\n",
       "      <td>0.324630</td>\n",
       "      <td>0.003218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>207.213374</td>\n",
       "      <td>1.853547</td>\n",
       "      <td>0.027019</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100, 's...</td>\n",
       "      <td>0.446906</td>\n",
       "      <td>0.453353</td>\n",
       "      <td>0.456359</td>\n",
       "      <td>0.452387</td>\n",
       "      <td>0.448486</td>\n",
       "      <td>0.478574</td>\n",
       "      <td>0.478800</td>\n",
       "      <td>0.472765</td>\n",
       "      <td>0.461486</td>\n",
       "      <td>0.427483</td>\n",
       "      <td>0.457660</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>22</td>\n",
       "      <td>0.319340</td>\n",
       "      <td>0.317542</td>\n",
       "      <td>0.318447</td>\n",
       "      <td>0.311060</td>\n",
       "      <td>0.317233</td>\n",
       "      <td>0.310918</td>\n",
       "      <td>0.315784</td>\n",
       "      <td>0.314921</td>\n",
       "      <td>0.315504</td>\n",
       "      <td>0.314557</td>\n",
       "      <td>0.315531</td>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>266.177373</td>\n",
       "      <td>1.867642</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100, 's...</td>\n",
       "      <td>0.440102</td>\n",
       "      <td>0.467965</td>\n",
       "      <td>0.454313</td>\n",
       "      <td>0.462176</td>\n",
       "      <td>0.449464</td>\n",
       "      <td>0.442454</td>\n",
       "      <td>0.467006</td>\n",
       "      <td>0.460446</td>\n",
       "      <td>0.433539</td>\n",
       "      <td>0.425432</td>\n",
       "      <td>0.450290</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>24</td>\n",
       "      <td>0.321937</td>\n",
       "      <td>0.318151</td>\n",
       "      <td>0.326080</td>\n",
       "      <td>0.324482</td>\n",
       "      <td>0.324001</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.322586</td>\n",
       "      <td>0.324971</td>\n",
       "      <td>0.323794</td>\n",
       "      <td>0.325245</td>\n",
       "      <td>0.323282</td>\n",
       "      <td>0.002198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_learning_rate param_n_estimators param_subsample                                             params  split0_test_score  split1_test_score  split2_test_score  split3_test_score  split4_test_score  split5_test_score  split6_test_score  split7_test_score  split8_test_score  split9_test_score  mean_test_score  std_test_score  rank_test_score  split0_train_score  split1_train_score  split2_train_score  split3_train_score  split4_train_score  split5_train_score  split6_train_score  split7_train_score  split8_train_score  split9_train_score  mean_train_score  std_train_score\n",
       "0       35.026700      0.260215         0.020645        0.001842                0.01                 25             0.6  {'learning_rate': 0.01, 'n_estimators': 25, 's...           0.793623           0.835415           0.847920           0.896416           0.859655           0.872369           0.852670           0.859224           0.811521           0.722943         0.835176        0.046543                3            0.835802            0.829987            0.829317            0.825115            0.828734            0.827507            0.828922            0.828876            0.833301            0.841282          0.830884         0.004457\n",
       "1       48.980678      0.179243         0.021446        0.003313                0.01                 25             0.8  {'learning_rate': 0.01, 'n_estimators': 25, 's...           0.792276           0.834645           0.848725           0.897813           0.859753           0.873130           0.853809           0.859678           0.812362           0.723347         0.835554        0.046866                2            0.835145            0.829911            0.830259            0.826020            0.829009            0.827749            0.829333            0.829420            0.833678            0.842273          0.831280         0.004438\n",
       "2       63.139601      0.174975         0.020246        0.002188                0.01                 25               1  {'learning_rate': 0.01, 'n_estimators': 25, 's...           0.793491           0.836605           0.850004           0.897684           0.860523           0.872942           0.854786           0.860192           0.813067           0.724227         0.836352        0.046616                1            0.835808            0.830953            0.830612            0.825974            0.829575            0.828113            0.830659            0.830416            0.834267            0.842854          0.831923         0.004495\n",
       "3       65.704232      0.366242         0.021243        0.002603                0.01                 50             0.6  {'learning_rate': 0.01, 'n_estimators': 50, 's...           0.686398           0.729281           0.740950           0.784217           0.744700           0.755264           0.743823           0.752846           0.709048           0.632479         0.727901        0.040539                6            0.724301            0.719675            0.720222            0.716070            0.718915            0.718778            0.718094            0.719638            0.723139            0.728912          0.720774         0.003519\n",
       "4       93.308612      0.591235         0.022440        0.003995                0.01                 50             0.8  {'learning_rate': 0.01, 'n_estimators': 50, 's...           0.687524           0.729157           0.742185           0.785097           0.746512           0.756830           0.744769           0.754083           0.708505           0.633188         0.728785        0.040743                5            0.725322            0.720638            0.720687            0.716899            0.720208            0.719302            0.719525            0.719583            0.723224            0.729401          0.721479         0.003415\n",
       "5      122.811179      2.825839         0.023441        0.005317                0.01                 50               1  {'learning_rate': 0.01, 'n_estimators': 50, 's...           0.688819           0.731255           0.743636           0.785578           0.748515           0.758541           0.749193           0.755434           0.711169           0.635479         0.730762        0.040532                4            0.725792            0.721824            0.721694            0.718104            0.720822            0.719624            0.721509            0.721375            0.724293            0.730703          0.722574         0.003392\n",
       "6      127.176602      0.657280         0.023234        0.002898                0.01                100             0.6  {'learning_rate': 0.01, 'n_estimators': 100, '...           0.568273           0.609148           0.615579           0.650875           0.616295           0.626036           0.621840           0.630985           0.588915           0.536907         0.606485        0.031599                9            0.598896            0.594475            0.595492            0.593178            0.594913            0.593920            0.593249            0.594110            0.597505            0.600256          0.595599         0.002331\n",
       "7      183.508827      2.019694         0.024136        0.002884                0.01                100             0.8  {'learning_rate': 0.01, 'n_estimators': 100, '...           0.570881           0.610511           0.617340           0.651913           0.618751           0.627068           0.625806           0.634607           0.592824           0.540086         0.608979        0.031204                8            0.600118            0.595250            0.596368            0.593787            0.595958            0.595801            0.595098            0.595304            0.598921            0.601620          0.596822         0.002392\n",
       "8      244.027693      4.153268         0.025036        0.004423                0.01                100               1  {'learning_rate': 0.01, 'n_estimators': 100, '...           0.573845           0.614277           0.619723           0.654454           0.621876           0.631284           0.631811           0.636000           0.595574           0.542894         0.612174        0.031314                7            0.602331            0.597571            0.598717            0.595456            0.597651            0.596914            0.597264            0.597888            0.600343            0.603150          0.598728         0.002334\n",
       "9       36.743908      0.310640         0.021844        0.000709                 0.1                 25             0.6  {'learning_rate': 0.1, 'n_estimators': 25, 'su...           0.471503           0.503909           0.492954           0.520262           0.493690           0.503152           0.510018           0.515324           0.482824           0.459660         0.495330        0.018376               12            0.479521            0.474608            0.475232            0.475141            0.475220            0.473677            0.473581            0.473298            0.476865            0.476409          0.475355         0.001777\n",
       "10      51.146483      0.209953         0.021935        0.003723                 0.1                 25             0.8  {'learning_rate': 0.1, 'n_estimators': 25, 'su...           0.466046           0.506826           0.500463           0.518280           0.494692           0.504979           0.516876           0.518299           0.479048           0.467791         0.497330        0.019004               11            0.477325            0.472973            0.478112            0.475059            0.475316            0.473738            0.475928            0.473985            0.475087            0.476761          0.475428         0.001551\n",
       "11      66.123022      0.351047         0.020448        0.001200                 0.1                 25               1  {'learning_rate': 0.1, 'n_estimators': 25, 'su...           0.471722           0.507161           0.504648           0.516913           0.501770           0.511015           0.518977           0.518706           0.488607           0.465871         0.500539        0.018124               10            0.477839            0.472340            0.476444            0.474636            0.476254            0.474227            0.475867            0.475000            0.477477            0.477282          0.475737         0.001618\n",
       "12      71.318518      0.339837         0.023440        0.002792                 0.1                 50             0.6  {'learning_rate': 0.1, 'n_estimators': 50, 'su...           0.439986           0.476449           0.459951           0.476676           0.456920           0.469860           0.479168           0.477123           0.447666           0.436844         0.462064        0.015370               17            0.432302            0.428650            0.427210            0.429360            0.429112            0.430893            0.428568            0.428492            0.433454            0.429595          0.429764         0.001810\n",
       "13     100.970703      0.817812         0.021740        0.002224                 0.1                 50             0.8  {'learning_rate': 0.1, 'n_estimators': 50, 'su...           0.439179           0.477934           0.464143           0.474561           0.460959           0.470529           0.476716           0.483702           0.452520           0.439758         0.464000        0.014977               16            0.433044            0.429475            0.428821            0.429363            0.429462            0.427397            0.430502            0.426507            0.431383            0.431163          0.429712         0.001825\n",
       "14     133.224521      0.474954         0.023936        0.005352                 0.1                 50               1  {'learning_rate': 0.1, 'n_estimators': 50, 'su...           0.440732           0.477874           0.468436           0.473313           0.464720           0.475059           0.486852           0.482636           0.448457           0.441451         0.465953        0.015952               14            0.431530            0.427822            0.430463            0.430221            0.431784            0.430338            0.430546            0.430617            0.433477            0.431479          0.430828         0.001369\n",
       "15     141.635818      0.927409         0.023633        0.002682                 0.1                100             0.6  {'learning_rate': 0.1, 'n_estimators': 100, 's...           0.424906           0.454803           0.446613           0.449875           0.435578           0.453268           0.458387           0.459560           0.424557           0.420650         0.442820        0.014276               27            0.396716            0.392756            0.393148            0.394692            0.394976            0.394087            0.394239            0.392806            0.396626            0.393133          0.394318         0.001386\n",
       "16     203.647532      0.874588         0.024833        0.003381                 0.1                100             0.8  {'learning_rate': 0.1, 'n_estimators': 100, 's...           0.428418           0.462285           0.447050           0.449792           0.439475           0.454408           0.454086           0.467198           0.426213           0.418003         0.444693        0.015415               26            0.398491            0.390450            0.394292            0.394044            0.395993            0.394809            0.392360            0.393985            0.393613            0.395300          0.394334         0.002023\n",
       "17     268.515495      2.265846         0.025522        0.004090                 0.1                100               1  {'learning_rate': 0.1, 'n_estimators': 100, 's...           0.428827           0.458377           0.456178           0.453847           0.445416           0.457971           0.468980           0.466510           0.433451           0.424664         0.449422        0.014837               25            0.399886            0.396361            0.399290            0.398690            0.401677            0.400767            0.399391            0.400549            0.402911            0.401658          0.400118         0.001750\n",
       "18      39.037271      0.148001         0.023441        0.004961                 0.5                 25             0.6  {'learning_rate': 0.5, 'n_estimators': 25, 'su...           0.464373           0.478686           0.473885           0.472001           0.453857           0.476461           0.472478           0.485331           0.442001           0.437044         0.465612        0.015321               15            0.409413            0.401205            0.409182            0.405584            0.408256            0.402039            0.409532            0.403353            0.408962            0.410206          0.406773         0.003251\n",
       "19      54.843581      0.254365         0.021642        0.002232                 0.5                 25             0.8  {'learning_rate': 0.5, 'n_estimators': 25, 'su...           0.458582           0.476451           0.452756           0.454928           0.459239           0.465811           0.478436           0.488447           0.439983           0.426602         0.460124        0.017465               19            0.395318            0.396745            0.399573            0.395745            0.404031            0.398760            0.397987            0.401996            0.398767            0.404609          0.399353         0.003085\n",
       "20      70.912507      0.331270         0.022539        0.002148                 0.5                 25               1  {'learning_rate': 0.5, 'n_estimators': 25, 'su...           0.447771           0.479785           0.459381           0.466389           0.460773           0.451288           0.476011           0.461441           0.445243           0.444882         0.459296        0.011655               20            0.400404            0.398188            0.400619            0.399534            0.398079            0.400212            0.395548            0.395555            0.403170            0.400795          0.399210         0.002276\n",
       "21      74.172988      0.228979         0.022737        0.003620                 0.5                 50             0.6  {'learning_rate': 0.5, 'n_estimators': 50, 'su...           0.473403           0.485087           0.478022           0.459726           0.447096           0.480777           0.478438           0.481021           0.461619           0.437770         0.468296        0.015240               13            0.376583            0.367501            0.370057            0.366428            0.367339            0.370303            0.366576            0.366766            0.372662            0.372880          0.369709         0.003259\n",
       "22     106.211889      0.608226         0.023228        0.002778                 0.5                 50             0.8  {'learning_rate': 0.5, 'n_estimators': 50, 'su...           0.446506           0.465813           0.469962           0.469316           0.453004           0.465493           0.479554           0.457857           0.441126           0.431228         0.457986        0.014183               21            0.363619            0.359818            0.358182            0.361736            0.363987            0.364170            0.359645            0.368082            0.361589            0.370872          0.363170         0.003720\n",
       "23     138.797165      0.921752         0.025627        0.003422                 0.5                 50               1  {'learning_rate': 0.5, 'n_estimators': 50, 'su...           0.441341           0.473234           0.455245           0.455810           0.454524           0.447482           0.473880           0.461614           0.440186           0.429673         0.453299        0.013449               23            0.364249            0.363261            0.369107            0.366069            0.365426            0.363936            0.365985            0.365002            0.368040            0.367239          0.365831         0.001767\n",
       "24     144.850668      0.594397         0.023840        0.003005                 0.5                100             0.6  {'learning_rate': 0.5, 'n_estimators': 100, 's...           0.470542           0.471541           0.472078           0.448189           0.462799           0.470592           0.467711           0.478045           0.440419           0.426837         0.460875        0.015844               18            0.323526            0.322026            0.319297            0.327097            0.323586            0.328347            0.320852            0.330037            0.325919            0.325612          0.324630         0.003218\n",
       "25     207.213374      1.853547         0.027019        0.003840                 0.5                100             0.8  {'learning_rate': 0.5, 'n_estimators': 100, 's...           0.446906           0.453353           0.456359           0.452387           0.448486           0.478574           0.478800           0.472765           0.461486           0.427483         0.457660        0.015118               22            0.319340            0.317542            0.318447            0.311060            0.317233            0.310918            0.315784            0.314921            0.315504            0.314557          0.315531         0.002694\n",
       "26     266.177373      1.867642         0.025333        0.002451                 0.5                100               1  {'learning_rate': 0.5, 'n_estimators': 100, 's...           0.440102           0.467965           0.454313           0.462176           0.449464           0.442454           0.467006           0.460446           0.433539           0.425432         0.450290        0.013845               24            0.321937            0.318151            0.326080            0.324482            0.324001            0.321570            0.322586            0.324971            0.323794            0.325245          0.323282         0.002198"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'index')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_filtered3_gb.boxplot()\n",
    "plt.title(\"gardient boosting\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.xlabel(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "      <th>gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.600969</td>\n",
       "      <td>0.752316</td>\n",
       "      <td>0.446906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.567533</td>\n",
       "      <td>0.744250</td>\n",
       "      <td>0.453353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.600193</td>\n",
       "      <td>0.730146</td>\n",
       "      <td>0.456359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.615376</td>\n",
       "      <td>0.784587</td>\n",
       "      <td>0.452387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.657021</td>\n",
       "      <td>0.864726</td>\n",
       "      <td>0.448486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>0.610207</td>\n",
       "      <td>0.827475</td>\n",
       "      <td>0.478574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>0.637492</td>\n",
       "      <td>0.804027</td>\n",
       "      <td>0.478800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>0.624472</td>\n",
       "      <td>0.760041</td>\n",
       "      <td>0.472765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>0.531306</td>\n",
       "      <td>0.687692</td>\n",
       "      <td>0.461486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>0.519839</td>\n",
       "      <td>0.667873</td>\n",
       "      <td>0.427483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ridge     lasso        gb\n",
       "split0_test_score  0.600969  0.752316  0.446906\n",
       "split1_test_score  0.567533  0.744250  0.453353\n",
       "split2_test_score  0.600193  0.730146  0.456359\n",
       "split3_test_score  0.615376  0.784587  0.452387\n",
       "split4_test_score  0.657021  0.864726  0.448486\n",
       "split5_test_score  0.610207  0.827475  0.478574\n",
       "split6_test_score  0.637492  0.804027  0.478800\n",
       "split7_test_score  0.624472  0.760041  0.472765\n",
       "split8_test_score  0.531306  0.687692  0.461486\n",
       "split9_test_score  0.519839  0.667873  0.427483"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualization 3: box plot\n",
    "# Comapring the 10CV performance of three regressor's optimal hyperparameters\n",
    "\n",
    "# Ridge: param_alpha = 5.0\n",
    "# Lasso: param_alpha = 0.01\n",
    "# Gardient Boosting: param_learning_rate = 0.5, param_n_estimators = 100, param_subsample = 0.8\n",
    "\n",
    "ridgecv = result_filtered3_ridge['5']\n",
    "lassocv = result_filtered3_lasso['0.01']\n",
    "gbcv = result_filtered3_gb['26']\n",
    "\n",
    "v3 = pd.concat([ridgecv, lassocv,gbcv], axis=1, join='inner')\n",
    "v3.columns = ['ridge','lasso','gb']\n",
    "v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'regressor')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization 3: box plot\n",
    "\n",
    "v3.boxplot()\n",
    "plt.title(\"model performance comparance among Ridge Regression, Lasso Regression and Gardient Boosting Regression\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.xlabel(\"regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thrid visualization is a box plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Best Model on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.5, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=0.8, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model: gradient boosting regression with learning_rate = 0.5, n_estimators = 100, subsample = 0.8\n",
    "\n",
    "best = GradientBoostingRegressor(learning_rate = 0.5, n_estimators = 100, subsample = 0.8)\n",
    "best.fit(X_test_preprocessed3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price    0.421124\n",
       "1        0.069406\n",
       "5        0.054944\n",
       "0        0.023814\n",
       "4        0.023604\n",
       "7        0.020715\n",
       "2        0.020245\n",
       "9        0.013535\n",
       "3        0.009372\n",
       "8        0.009358\n",
       "dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.Series(best.feature_importances_, index = X_test_preprocessed2.columns)\n",
    "top_10 = feature_importance.nlargest(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'feature name')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization 4: Bar Plot\n",
    "\n",
    "top_10_index = [\"price\",\"topic1\",\"topic5\",\"topic0\",\"topic4\",\"topic7\",\"topic2\",\"topic9\",\"topic3\",\"topic8\"]\n",
    "plt.bar(top_10_index,top_10.values)\n",
    "plt.title(\"top 10 fetures of the best model\")\n",
    "plt.ylabel(\"feature importance\")\n",
    "plt.xlabel(\"feature name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forth visualization is a bar plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
